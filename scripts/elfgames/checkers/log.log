Python version: 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) 
[GCC 7.2.0]
PyTorch version: 0.4.1.post2
CUDA version 9.0.176
Conda env: 
[1;32;40mSingleProcessRun.get_option_spec    [0m
[2019-01-11 13:22:49.369] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Loading env
[2019-01-11 13:22:49.373] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] [1;32;40mModule successfully loaded :[0m elfgames.go.game
[2019-01-11 13:22:49.373] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] [1;32;40mModule successfully loaded :[0m elfgames.go.df_model_checkers
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: get_option_spec
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: get_option_spec
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: __init__
Stats: Name  is not known!
[1;32;40mSingleProcessRun.get_option_spec    [0m
[2019-01-11 13:22:49.379] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Parsed options:
{'T': 1,
 'actor_only': False,
 'adam_eps': 0.001,
 'additional_labels': [],
 'backprop': True,
 'batchsize': 256,
 'batchsize2': -1,
 'black_use_policy_network_only': False,
 'bn': True,
 'bn_eps': 1e-05,
 'bn_momentum': 0.0,
 'cheat_eval_new_model_wins_half': False,
 'cheat_selfplay_random_result': False,
 'check_loaded_options': True,
 'checkers_num_future_actions': 1,
 'client_max_delay_sec': 1200,
 'comment': '',
 'data_aug': -1,
 'dim': 128,
 'dist_rank': -1,
 'dist_url': '',
 'dist_world_size': -1,
 'dump_record_prefix': '',
 'epsilon': 0.0,
 'eval_model_pair': '',
 'eval_num_games': 20,
 'eval_old_model': -1,
 'eval_winrate_thres': 0.55,
 'expected_num_clients': 1,
 'freq_update': 1,
 'gpu': 0,
 'keep_prev_selfplay': True,
 'keys_in_reply': ['checkers_V'],
 'latest_symlink': 'latest',
 'leaky_relu': False,
 'list_files': [],
 'load': '',
 'load_model_sleep_interval': 0.0,
 'loglevel': 'info',
 'lr': 0.01,
 'mcts_alpha': 0.03,
 'mcts_epsilon': 0.25,
 'mcts_persistent_tree': True,
 'mcts_pick_method': 'most_visited',
 'mcts_puct': 0.85,
 'mcts_rollout_per_batch': 1,
 'mcts_rollout_per_thread': 20,
 'mcts_root_unexplored_q_zero': False,
 'mcts_threads': 16,
 'mcts_unexplored_q_zero': False,
 'mcts_use_prior': True,
 'mcts_verbose': False,
 'mcts_verbose_time': False,
 'mcts_virtual_loss': 5,
 'mode': 'train',
 'momentum': 0.9,
 'move_cutoff': -1,
 'num_block': 10,
 'num_cooldown': 50,
 'num_episode': 3,
 'num_games': 8,
 'num_games_per_thread': -1,
 'num_minibatch': 128,
 'num_reader': 2,
 'num_reset_ranking': 5000,
 'omit_keys': [],
 'onload': [],
 'opt_method': 'sgd',
 'parameter_print': True,
 'parsed_args': ['./train.py',
                 '--server_id',
                 'myserver',
                 '--port',
                 '1234',
                 '--gpu',
                 '0',
                 '--mode',
                 'train',
                 '--batchsize',
                 '256',
                 '--num_minibatch',
                 '128',
                 '--num_games',
                 '8',
                 '--keys_in_reply',
                 'checkers_V',
                 '--T',
                 '1',
                 '--dim',
                 '128',
                 '--num_block',
                 '10',
                 '--use_mcts',
                 '--use_mcts_ai2',
                 '--mcts_epsilon',
                 '0.25',
                 '--mcts_persistent_tree',
                 '--mcts_puct',
                 '0.85',
                 '--mcts_use_prior',
                 '--mcts_threads',
                 '16',
                 '--mcts_rollout_per_thread',
                 '20',
                 '--mcts_virtual_loss',
                 '5',
                 '--mcts_alpha',
                 '0.03',
                 '--save_first',
                 '--use_data_parallel',
                 '--num_episode',
                 '3',
                 '--keep_prev_selfplay',
                 '--keep_prev_selfplay',
                 '--weight_decay',
                 '0.0002',
                 '--opt_method',
                 'sgd',
                 '--bn_momentum=0',
                 '--num_cooldown=50',
                 '--expected_num_client',
                 '1',
                 '--selfplay_async',
                 '--selfplay_init_num',
                 '2',
                 '--q_min_size',
                 '2',
                 '--q_max_size',
                 '4',
                 '--num_reader',
                 '2',
                 '--selfplay_update_num',
                 '10',
                 '--eval_winrate_thres',
                 '0.55',
                 '--eval_num_games',
                 '20',
                 '--lr',
                 '0.01',
                 '--momentum',
                 '0.9',
                 '--verbose'],
 'policy_distri_cutoff': 0,
 'policy_distri_training_for_all': False,
 'port': 1234,
 'print_result': False,
 'q_max_size': 4,
 'q_min_size': 2,
 'ratio_pre_moves': 0,
 'record_dir': './record',
 'replace_prefix': [],
 'sample_nodes': ['pi,a'],
 'sample_policy': 'epsilon-greedy',
 'save_dir': './myserver',
 'save_first': True,
 'save_prefix': 'save',
 'selfplay_async': True,
 'selfplay_init_num': 2,
 'selfplay_timeout_usec': 0,
 'selfplay_update_num': 10,
 'server_addr': '',
 'server_id': 'myserver',
 'start_ratio_pre_moves': 0.5,
 'store_greedy': False,
 'suicide_after_n_games': -1,
 'tqdm': False,
 'trainer_stats': '',
 'use_data_parallel': True,
 'use_data_parallel_distributed': False,
 'use_df_feature': False,
 'use_fp16': False,
 'use_mcts': True,
 'use_mcts_ai2': True,
 'verbose': True,
 'weight_decay': 0.0002,
 'white_mcts_rollout_per_batch': -1,
 'white_mcts_rollout_per_thread': -1,
 'white_puct': -1.0,
 'white_use_policy_network_only': False}
[2019-01-11 13:22:49.380] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Finished loading env
[2019-01-11 13:22:49.380] [elf::legacy::ContextOptions-0  ] [info] JobId: local
[2019-01-11 13:22:49.380] [elf::legacy::ContextOptions-0  ] [info] #Game: 8
[2019-01-11 13:22:49.380] [elf::legacy::ContextOptions-0  ] [info] T: 1
[2019-01-11 13:22:49.380] [elf::legacy::ContextOptions-0  ] [info] [#th=16][rl=20][per=1][eps=0.25][alpha=0.03][prior=1][c_puct=0.85][uqz=0][r_uqz=0]
[2019-01-11 13:22:49.380] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing replay_buffer(ReplayBuffer) info : #Queue: 2, spec: ReaderQueue: Queue [min=2][max=4], Length: 0, 0, Total: 0, MinSizeSatisfied: 0
[2019-01-11 13:22:49.380] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing threaded_ctrl_(ThreadedCtrl)
[2019-01-11 13:22:49.380] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing client_mgr_(ClientManager)
[2019-01-11 13:22:49.380] [[1;35;40m|++|[0mDistriServer-10 ] [info] Finished initializing trainCtrl_(TrainCtrl)
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mDataOnlineLoader-17 ] [info] ZMQVer: 4.2.5 Reader[db=data-1547212969.db] [local] Connect to [127.0.0.1]:1234, ipv6: True, verbose: True
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mDistriServer-10 ] [info] Finished initializing onlineLoader_(DataOnlineLoader)
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mDistriServer-10 ] [info] [1;32;40mDistriServer successfully created[0m

[2019-01-11 13:22:49.381] [elf::distributed::Reader-21 ] [info] Reader: [0;33;40mno message[0m, Stats: 0/0/0, wait for 15 sec ... 
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mServerGameTrain-0-23 ] [info] Was succefully created
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mServerGameTrain-1-89 ] [info] Was succefully created
[2019-01-11 13:22:49.381] [[1;35;40m|++|[0mServerGameTrain-2-155] [info] Was succefully created
[2019-01-11 13:22:49.382] [[1;35;40m|++|[0mServerGameTrain-3-221] [info] Was succefully created
[2019-01-11 13:22:49.382] [[1;35;40m|++|[0mServerGameTrain-4-287] [info] Was succefully created
[2019-01-11 13:22:49.382] [[1;35;40m|++|[0mServerGameTrain-5-353] [info] Was succefully created
[2019-01-11 13:22:49.383] [[1;35;40m|++|[0mServerGameTrain-6-419] [info] Was succefully created
[2019-01-11 13:22:49.383] [[1;35;40m|++|[0mServerGameTrain-7-485] [info] Was succefully created
[2019-01-11 13:22:49.383] [[1;35;40m|++|[0mGameContext-1  ] [info] 8 ServerGameTrain was created
****************** Options ******************
Seed: 0
Time signature: 190111-132249
Client max delay in sec: 1200
#FutureActions: 1
#GamePerThread: -1
mode: train
Selfplay init min #games: 2, update #games: 10, async: True
UseMCTS: True
Data Aug: -1
Start_ratio_pre_moves: 0.5
ratio_pre_moves: 0
MoveCutOff: -1
Use DF feature: False
PolicyDistriCutOff: 0
Expected #client: 1
Server_addr: [127.0.0.1], server_id: myserver, port: 1234
#Reader: 2, Qmin_sz: 2, Qmax_sz: 4
Verbose: True
Policy distri training for all moves: False
Reset move ranking after 5000 actions


*********************************************
Version:  8649f6013d9994a7c09ca9db1456c00249e43e24_unstaged
*********************************************
Mode:  train
checkers_num_action:  170
train: {'input': ['checkers_s', 'checkers_offline_a', 'checkers_winner', 'checkers_mcts_scores', 'checkers_move_idx', 'checkers_selfplay_ver'], 'reply': None}
SharedMem: "train", keys: ['checkers_offline_a', 'checkers_move_idx', 'checkers_winner', 'checkers_selfplay_ver', 'checkers_s', 'checkers_mcts_scores']
train_ctrl: {'input': ['checkers_selfplay_ver'], 'reply': None, 'batchsize': 1}
SharedMem: "train_ctrl", keys: ['checkers_selfplay_ver']
[2019-01-11 13:22:51.686] [[1;35;40m|++|[0mThreadedCtrl-13 ] [info] Setting init version: 0
[2019-01-11 13:22:51.686] [[1;35;40m|++|[0mEvalSubCtrl-15 ] [info] Set new baseline model, ver: 0
[2019-01-11 13:22:51.686] [[1;35;40m|++|[0mSelfPlaySubCtrl-14 ] [info] SelfPlay: -1 -> 0
Save models in		: "./myserver"
Keep prev_selfplay	: True
[2019-01-11 13:22:51.719] [[1;31;40m|py|[0mrlpytorch.trainer.ModelSaver-5  ] [info] Saved new model: [./myserver/save-0.bin]

[2019-01-11 13:22:51.719] [elf::base::Context-3  ] [info] Prepare context to start
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-22 ] [info] mainLoop was started [0] Seed: 31226757, thread_id: 18050729993239014226
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-88 ] [info] mainLoop was started [1] Seed: 33568236, thread_id: 2950227612526216400
[2019-01-11 13:22:51.719] [[1;31;40m|py|[0melfgames.checkers.train-0  ] [info] after_start
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mThreadedCtrl-13 ] [info] [1;37;40mInsufficient sample[0m for model 0... waiting 30s
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-154] [info] mainLoop was started [2] Seed: 35909715, thread_id: 15826205378796634110
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-220] [info] mainLoop was started [3] Seed: 38251194, thread_id: 1609452121355541399
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-286] [info] mainLoop was started [4] Seed: 40592674, thread_id: 4368650403364434212
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-352] [info] mainLoop was started [5] Seed: 42934153, thread_id: 11887451860319303826
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-418] [info] mainLoop was started [6] Seed: 45275632, thread_id: 2460251725763060024
[2019-01-11 13:22:51.719] [[1;35;40m|++|[0mGameBase-484] [info] mainLoop was started [7] Seed: 47617112, thread_id: 17074063511641555932
Python version: 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) 
[GCC 7.2.0]
PyTorch version: 0.4.1.post2
CUDA version 9.0.176
Conda env: 
[1;32;40mSingleProcessRun.get_option_spec    [0m
[2019-01-11 15:39:37.774] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Loading env
[2019-01-11 15:39:37.782] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] [1;32;40mModule successfully loaded :[0m elfgames.go.game
[2019-01-11 15:39:37.783] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] [1;32;40mModule successfully loaded :[0m elfgames.go.df_model_checkers
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: get_option_spec
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: get_option_spec
[1;31;40m|py|[0m[1;37;40m MCTSPrediction:: __init__
Stats: Name  is not known!
[1;32;40mSingleProcessRun.get_option_spec    [0m
[2019-01-11 15:39:37.791] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Parsed options:
{'T': 1,
 'actor_only': False,
 'adam_eps': 0.001,
 'additional_labels': [],
 'backprop': True,
 'batchsize': 256,
 'batchsize2': -1,
 'black_use_policy_network_only': False,
 'bn': True,
 'bn_eps': 1e-05,
 'bn_momentum': 0.0,
 'cheat_eval_new_model_wins_half': False,
 'cheat_selfplay_random_result': False,
 'check_loaded_options': True,
 'checkers_num_future_actions': 1,
 'client_max_delay_sec': 1200,
 'comment': '',
 'data_aug': -1,
 'dim': 128,
 'dist_rank': -1,
 'dist_url': '',
 'dist_world_size': -1,
 'dump_record_prefix': '',
 'epsilon': 0.0,
 'eval_model_pair': '',
 'eval_num_games': 20,
 'eval_old_model': -1,
 'eval_winrate_thres': 0.55,
 'expected_num_clients': 1,
 'freq_update': 1,
 'gpu': 0,
 'keep_prev_selfplay': True,
 'keys_in_reply': ['checkers_V'],
 'latest_symlink': 'latest',
 'leaky_relu': False,
 'list_files': [],
 'load': '',
 'load_model_sleep_interval': 0.0,
 'loglevel': 'info',
 'lr': 0.01,
 'mcts_alpha': 0.03,
 'mcts_epsilon': 0.25,
 'mcts_persistent_tree': True,
 'mcts_pick_method': 'most_visited',
 'mcts_puct': 0.85,
 'mcts_rollout_per_batch': 1,
 'mcts_rollout_per_thread': 20,
 'mcts_root_unexplored_q_zero': False,
 'mcts_threads': 16,
 'mcts_unexplored_q_zero': False,
 'mcts_use_prior': True,
 'mcts_verbose': False,
 'mcts_verbose_time': False,
 'mcts_virtual_loss': 5,
 'mode': 'train',
 'momentum': 0.9,
 'move_cutoff': -1,
 'num_block': 10,
 'num_cooldown': 50,
 'num_episode': 3,
 'num_games': 8,
 'num_games_per_thread': -1,
 'num_minibatch': 128,
 'num_reader': 2,
 'num_reset_ranking': 5000,
 'omit_keys': [],
 'onload': [],
 'opt_method': 'sgd',
 'parameter_print': True,
 'parsed_args': ['./train.py',
                 '--server_id',
                 'myserver',
                 '--port',
                 '1234',
                 '--gpu',
                 '0',
                 '--mode',
                 'train',
                 '--batchsize',
                 '256',
                 '--num_minibatch',
                 '128',
                 '--num_games',
                 '8',
                 '--keys_in_reply',
                 'checkers_V',
                 '--T',
                 '1',
                 '--dim',
                 '128',
                 '--num_block',
                 '10',
                 '--use_mcts',
                 '--use_mcts_ai2',
                 '--mcts_epsilon',
                 '0.25',
                 '--mcts_persistent_tree',
                 '--mcts_puct',
                 '0.85',
                 '--mcts_use_prior',
                 '--mcts_threads',
                 '16',
                 '--mcts_rollout_per_thread',
                 '20',
                 '--mcts_virtual_loss',
                 '5',
                 '--mcts_alpha',
                 '0.03',
                 '--save_first',
                 '--use_data_parallel',
                 '--num_episode',
                 '3',
                 '--keep_prev_selfplay',
                 '--keep_prev_selfplay',
                 '--weight_decay',
                 '0.0002',
                 '--opt_method',
                 'sgd',
                 '--bn_momentum=0',
                 '--num_cooldown=50',
                 '--expected_num_client',
                 '1',
                 '--selfplay_async',
                 '--selfplay_init_num',
                 '2',
                 '--q_min_size',
                 '2',
                 '--q_max_size',
                 '4',
                 '--num_reader',
                 '2',
                 '--selfplay_update_num',
                 '10',
                 '--eval_winrate_thres',
                 '0.55',
                 '--eval_num_games',
                 '20',
                 '--lr',
                 '0.01',
                 '--momentum',
                 '0.9',
                 '--verbose'],
 'policy_distri_cutoff': 0,
 'policy_distri_training_for_all': False,
 'port': 1234,
 'print_result': False,
 'q_max_size': 4,
 'q_min_size': 2,
 'ratio_pre_moves': 0,
 'record_dir': './record',
 'replace_prefix': [],
 'sample_nodes': ['pi,a'],
 'sample_policy': 'epsilon-greedy',
 'save_dir': './myserver',
 'save_first': True,
 'save_prefix': 'save',
 'selfplay_async': True,
 'selfplay_init_num': 2,
 'selfplay_timeout_usec': 0,
 'selfplay_update_num': 10,
 'server_addr': '',
 'server_id': 'myserver',
 'start_ratio_pre_moves': 0.5,
 'store_greedy': False,
 'suicide_after_n_games': -1,
 'tqdm': False,
 'trainer_stats': '',
 'use_data_parallel': True,
 'use_data_parallel_distributed': False,
 'use_df_feature': False,
 'use_fp16': False,
 'use_mcts': True,
 'use_mcts_ai2': True,
 'verbose': True,
 'weight_decay': 0.0002,
 'white_mcts_rollout_per_batch': -1,
 'white_mcts_rollout_per_thread': -1,
 'white_puct': -1.0,
 'white_use_policy_network_only': False}
[2019-01-11 15:39:37.791] [[1;31;40m|py|[0mrlpytorch.model_loader.load_env1  ] [info] Finished loading env
[2019-01-11 15:39:37.791] [elf::legacy::ContextOptions-0  ] [info] JobId: local
[2019-01-11 15:39:37.791] [elf::legacy::ContextOptions-0  ] [info] #Game: 8
[2019-01-11 15:39:37.791] [elf::legacy::ContextOptions-0  ] [info] T: 1
[2019-01-11 15:39:37.791] [elf::legacy::ContextOptions-0  ] [info] [#th=16][rl=20][per=1][eps=0.25][alpha=0.03][prior=1][c_puct=0.85][uqz=0][r_uqz=0]
[2019-01-11 15:39:37.792] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing replay_buffer(ReplayBuffer) info : #Queue: 2, spec: ReaderQueue: Queue [min=2][max=4], Length: 0, 0, Total: 0, MinSizeSatisfied: 0
[2019-01-11 15:39:37.792] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing threaded_ctrl_(ThreadedCtrl)
[2019-01-11 15:39:37.792] [[1;35;40m|++|[0mTrainCtrl-11 ] [info] Finished initializing client_mgr_(ClientManager)
[2019-01-11 15:39:37.792] [[1;35;40m|++|[0mDistriServer-10 ] [info] Finished initializing trainCtrl_(TrainCtrl)
Traceback (most recent call last):
  File "./train.py", line 172, in <module>
    main()
  File "./train.py", line 52, in main
    GC = env["game"].initialize()
  File "/home/ubuntu/arvi_dima/elf/elf_our_clean_version/src_py/elfgames/go/game.py", line 334, in initialize
    co, GC, opt = self._set_params()
  File "/home/ubuntu/arvi_dima/elf/elf_our_clean_version/src_py/elfgames/go/game.py", line 322, in _set_params
    GC = go.GameContext(co, opt)
RuntimeError: Address already in use
